{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to put the urls in chronological order if you want to specify stop date. only works 1 region at a time\n",
    "url_lst = ['https://docs.google.com/spreadsheets/d/1-ldl2hBdKog95GqqrxTcNdmHtimAFg1LrNPVZKTyUUg/edit#gid=311031188', \n",
    "'https://docs.google.com/spreadsheets/d/1vJG2UopyZIfDzLAPQ_jrb_WQ_I0lI3ACW0WbQ9HK-os/edit#gid=311031188'\n",
    "]\n",
    "\n",
    "sheet_lst = []\n",
    "\n",
    "counter = 0\n",
    "for i in url_lst:\n",
    "    if counter == 0:\n",
    "        sheet_url = i\n",
    "        url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "        df = pd.read_csv(url).reset_index(drop=True)\n",
    "        sheet_lst.append(df)\n",
    "\n",
    "    else:\n",
    "        sheet_url = i\n",
    "        url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "        df = pd.read_csv(url).reset_index(drop=True)\n",
    "        sheet_lst.append(df[df.columns[5:]])\n",
    "    counter += 1\n",
    "\n",
    "if len(url_lst) > 1:\n",
    "    df = pd.concat(sheet_lst, axis=1).T.reset_index().T\n",
    "elif len(url_lst) == 1:\n",
    "    df = df.T.reset_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_check_state(df, stop_date):\n",
    "    \"\"\"\n",
    "    df: Google Sheet that has been converted to a DataFrame\n",
    "    stop_date: Date to stop at as a str (M/DD/YYYY), empty string otherwise (''). Eg: If you want to stop at '4/15/2022', stop_date = '4/16/2022'\n",
    "    output: dictionary indexed by state with values as a list of dates missing data\n",
    "    \"\"\"\n",
    "    nan_okay = ['GA', 'IN', 'MI', 'CT', 'ND', 'VA', 'MA', 'ME', 'TX', 'VT', 'TN', 'PA', 'CA', 'PR', 'MN', 'WA', 'WI', 'IL', 'OH', 'CO', 'DE']\n",
    "    filtered = df.loc[(~df[4].isin(nan_okay)) & (df[3] != np.nan) & (df[3].str.contains(',')) &\n",
    "         (df[3].str.contains('District of Columbia') == False) & (df[3].str.contains('(state)') == False)].reset_index()\n",
    "    first_row = pd.DataFrame(df.iloc[0]).T\n",
    "    df = first_row.append(filtered, ignore_index=True)\n",
    "    counties = df[3]\n",
    "    state = df[4]\n",
    "    missing_dict = {}\n",
    "    counter_key = {0:'tstpos', 1:'pbpos', 2:'mort', 3:'pbmort'}\n",
    "    counter = 0\n",
    "    state_counts = df.groupby(4).count()[3]\n",
    "\n",
    "    for i in df.loc[:,5:]:\n",
    "        \n",
    "        # keeps track of current date and if it matches the stop date, end the loop\n",
    "        if 'Unnamed' not in str(df[i].iloc[0]):\n",
    "            curr_date = str(df[i].iloc[0])\n",
    "            counter = 0\n",
    "            if curr_date == stop_date:\n",
    "                break\n",
    "\n",
    "        curr_col = df[i]\n",
    "        # list of the indices with a NaN value\n",
    "        null_idx = np.where(curr_col.isnull())[0]\n",
    "\n",
    "        # loops over list of NaN values if it is not an empty list\n",
    "        if len(null_idx > 0):\n",
    "            for j in null_idx:\n",
    "                nan_state = state[j]\n",
    "                nan_county = counties[j]\n",
    "                \n",
    "\n",
    "                # to add counties also change dict value to (curr_date, nan_county)\n",
    "                # adds the state and date to the output dictionary \n",
    "                nan_state = nan_county.split(',')[-1]\n",
    "                if nan_state in missing_dict.keys():   \n",
    "                    if curr_date not in missing_dict[nan_state]:\n",
    "                        missing_dict[nan_state] += [curr_date]\n",
    "                elif nan_state not in missing_dict.keys():\n",
    "                    missing_dict[nan_state] = [curr_date]\n",
    "        counter += 1\n",
    "\n",
    "    return missing_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_check_county(df, stop_date):\n",
    "    \"\"\"\n",
    "    df: Google Sheet that has been converted to a DataFrame\n",
    "    stop_date: Date to stop at as a str (M/DD/YYYY), empty string otherwise (''). Eg: If you want to stop at '4/15/2022', stop_date = '4/16/2022'\n",
    "    output: dictionary indexed by state with values as list of tuples containing date, county, and column (mort, pbmort, tstpos, pbpos) the missing data is in\n",
    "    \"\"\"\n",
    "    nan_okay = ['GA', 'IN', 'MI', 'CT', 'ND', 'VA', 'MA', 'ME', 'TX', 'VT', 'TN', 'PA', 'CA', 'PR', 'MN', 'WA', 'WI', 'IL', 'OH', 'CO', 'DE']\n",
    "    filtered = df.loc[(~df[4].isin(nan_okay)) & (df[3] != np.nan) & (df[3].str.contains(',')) &\n",
    "         (df[3].str.contains('District of Columbia') == False) & (df[3].str.contains('(state)') == False)].reset_index()\n",
    "    first_row = pd.DataFrame(df.iloc[0]).T\n",
    "    df = first_row.append(filtered, ignore_index=True)\n",
    "    counties = df[3]\n",
    "    state = df[4]\n",
    "    missing_dict = {}\n",
    "    counter_key = {0:'tstpos', 1:'pbpos', 2:'mort', 3:'pbmort'}\n",
    "    counter = 0\n",
    "    state_counts = df.groupby(4).count()[3]\n",
    "\n",
    "    for i in df.loc[:,5:]:\n",
    "        \n",
    "        # keeps track of current date and if it matches the stop date, end the loop\n",
    "        if 'Unnamed' not in str(df[i].iloc[0]):\n",
    "            curr_date = str(df[i].iloc[0])\n",
    "            counter = 0\n",
    "            if curr_date == stop_date:\n",
    "                break\n",
    "\n",
    "        curr_col = df[i]\n",
    "        # list of the indices with a NaN value\n",
    "        null_idx = np.where(curr_col.isnull())[0]\n",
    "\n",
    "        # loops over list of NaN values if it is not an empty list\n",
    "        if len(null_idx > 0):\n",
    "            for j in null_idx:\n",
    "                nan_state = state[j]\n",
    "                nan_county = counties[j]\n",
    "\n",
    "                if nan_state in missing_dict.keys():\n",
    "                    missing_dict[nan_state] += [(curr_date, nan_county, counter_key[counter])]\n",
    "                elif nan_state not in missing_dict.keys():\n",
    "                    missing_dict[nan_state] = [(curr_date, nan_county, counter_key[counter])]\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    return missing_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New Jersey : ['9/12/2022', '9/13/2022', '9/14/2022', '9/15/2022', '9/17/2022', '9/18/2022', '9/26/2022', '9/27/2022', '9/28/2022', '9/29/2022', '9/30/2022', '10/1/2022', '10/2/2022', '10/10/2022', '10/11/2022', '10/12/2022']\n",
      " New York : ['9/12/2022', '9/13/2022', '9/14/2022', '9/15/2022', '9/16/2022', '9/17/2022', '9/18/2022', '9/19/2022', '9/20/2022', '9/21/2022', '9/22/2022', '9/23/2022', '9/24/2022', '9/25/2022', '9/26/2022', '9/27/2022', '9/28/2022', '9/29/2022', '9/30/2022', '10/1/2022', '10/2/2022', '10/3/2022', '10/4/2022', '10/5/2022', '10/6/2022', '10/7/2022', '10/8/2022', '10/9/2022', '10/10/2022', '10/11/2022', '10/12/2022', '10/13/2022', '10/14/2022', '10/15/2022']\n",
      " Rhode Island : ['9/12/2022', '9/13/2022', '9/14/2022', '9/15/2022', '9/19/2022', '9/20/2022', '9/21/2022', '9/26/2022', '9/27/2022', '9/28/2022', '9/29/2022', '9/30/2022', '10/1/2022', '10/2/2022', '10/3/2022', '10/4/2022', '10/5/2022', '10/6/2022', '10/7/2022', '10/8/2022', '10/9/2022', '10/10/2022', '10/11/2022', '10/12/2022', '10/13/2022', '10/14/2022', '10/15/2022']\n",
      " Maryland : ['9/26/2022', '9/27/2022', '9/28/2022', '9/29/2022', '9/30/2022', '10/1/2022', '10/2/2022', '10/6/2022', '10/10/2022', '10/11/2022', '10/12/2022']\n",
      " New Hampshire : ['9/30/2022', '10/1/2022', '10/2/2022', '10/6/2022', '10/10/2022', '10/11/2022', '10/12/2022']\n",
      " Kentucky : ['10/3/2022', '10/4/2022', '10/8/2022']\n",
      " North Carolina : ['10/5/2022', '10/6/2022', '10/7/2022', '10/8/2022', '10/9/2022', '10/10/2022', '10/11/2022']\n",
      " West Virginia : ['10/12/2022']\n",
      " West Virgina : ['10/12/2022']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/y1xn0yjj22v8l8rwlryfjdj00000gn/T/ipykernel_2758/759894756.py:9: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df[3].str.contains('District of Columbia') == False) & (df[3].str.contains('(state)') == False)].reset_index()\n",
      "/var/folders/jm/y1xn0yjj22v8l8rwlryfjdj00000gn/T/ipykernel_2758/759894756.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = first_row.append(filtered, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# use nan_check if you only need dates of missing data, nan_check_county if you need date, county, and column\n",
    "# input date should be the day after where it should stop at\n",
    "out = nan_check_state(df, '10/16/2022')\n",
    "if (len(out) == 1 and 'Unnamed' in list(out.keys())[0]) or len(out) == 0:\n",
    "    print('No Missing Data')\n",
    "for i in out:\n",
    "    if 'Unnamed' not in i:\n",
    "        print(i,':' ,out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
